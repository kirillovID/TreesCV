{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b91d3d-f9d4-43af-9ff9-2e86e2223f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import skimage\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as tr\n",
    "from torchvision.io import read_image\n",
    "from torchvision import models\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c23037c-ec65-47aa-a21f-76e992e92946",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66dac31b-2375-45e6-ac1b-9d48f9ac5277",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"./RGBaHa(26-03-23)\"\n",
    "images_folder = \"RGBaHa\"\n",
    "table_file = \"data.csv\"\n",
    "types_file = \"types.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09eeb6ff-11b6-47fd-86ab-6d9367aa30a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"latin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a346649-aa90-4c73-8ff1-6b94a5270de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeDataset(Dataset):\n",
    "    def __init__(self, imgs_path, table_path, types_path):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.types = pd.read_csv(types_path, index_col=0)\n",
    "        self.table = pd.read_csv(table_path, index_col=0, converters={\"latin\": lambda x: self.types.loc[x].type if x != \"NA\" else np.nan}).dropna()\n",
    "        self.label_map = {label: i for i, label in enumerate(self.table.latin.unique())}\n",
    "        self.table = self.table.replace({\"latin\": self.label_map})\n",
    "        \n",
    "        self.max_h, self.max_w = 0, 0\n",
    "        self.channel_mean, self.channel_std = 0, 0\n",
    "        self.depth_max = 0\n",
    "        images = []\n",
    "        \n",
    "        for tree_id in self.table.treeID:\n",
    "            file_path = os.path.join(imgs_path, f\"treeID_{tree_id}.tiff\")\n",
    "            img_rgbd = skimage.io.imread(file_path)[:, :, [0, 1, 2, 4]].transpose(2, 0, 1)[None, :, :, :]\n",
    "            self.max_h = max(self.max_h, img_rgbd.shape[2])\n",
    "            self.max_w = max(self.max_w, img_rgbd.shape[3])\n",
    "            images.append(torch.from_numpy(img_rgbd))\n",
    "            self.depth_max = max(self.depth_max, img_rgbd[:, 3, :, :].max())\n",
    "        \n",
    "        padded_images = []\n",
    "        for image in images:\n",
    "            image[:, :3, :, :] /= 255.\n",
    "            image[:, 3, :, :] /= self.depth_max\n",
    "            img_h, img_w = image.shape[2:]\n",
    "            h_pos = (self.max_h - img_h) // 2\n",
    "            w_pos = (self.max_w - img_w) // 2\n",
    "            padded = torch.zeros(1, 4, self.max_h, self.max_w)\n",
    "            padded[:, :, h_pos: h_pos+img_h, w_pos: w_pos+img_w] = image\n",
    "            padded_images.append(padded)            \n",
    "            \n",
    "            self.channel_mean += image.mean(dim=(0, 2, 3))\n",
    "            self.channel_std += image.std(dim=(0, 2, 3))\n",
    "\n",
    "        self.images = torch.cat(padded_images)\n",
    "        self.channel_mean /= len(self.images)\n",
    "        self.channel_std /= len(self.images)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.images[index].type(torch.FloatTensor)\n",
    "        y = torch.tensor(self.table.iloc[index].loc[target_column], dtype=torch.long)\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91072d67-1e5e-49f6-b298-5bd8003472b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeDatasetFromSubset(Dataset):\n",
    "    def __init__(self, subset, all_transform=None, rgb_transform=None):\n",
    "        self.subset = subset\n",
    "        self.all_transform = all_transform\n",
    "        self.rgb_transform = rgb_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.all_transform:\n",
    "            x = self.all_transform(x)\n",
    "        if self.rgb_transform:\n",
    "            x[:3, :, :] = self.rgb_transform(x[:3, :, :])\n",
    "        return x[:3, :, :], y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb1f33b1-a984-42f7-9460-19352a0c4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TreeDataset(os.path.join(data_folder, images_folder), \n",
    "                   os.path.join(data_folder, table_file), \n",
    "                   os.path.join(data_folder, types_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "746a3a5f-9982-4ccc-bbbc-7b8e1e0ac0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = random_split(data, [0.70, 0.20, 0.10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbdf6da4-2c9b-45fa-a444-f4be15ac2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=0.1):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3147fc50-4409-42e0-913b-e4183b98d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transform = tr.Compose([\n",
    "    tr.Normalize(data.channel_mean, data.channel_std),\n",
    "    tr.RandomHorizontalFlip(),\n",
    "    tr.RandomVerticalFlip(),\n",
    "    tr.RandomAffine(degrees=180),\n",
    "    # tr.RandomApply([AddGaussianNoise(),]),\n",
    "])\n",
    "rgb_transform = tr.Compose([\n",
    "    # tr.RandomAutocontrast(),\n",
    "    # tr.RandomAdjustSharpness(0.5),\n",
    "])\n",
    "\n",
    "prepare_transform = tr.Compose([\n",
    "    tr.Normalize(data.channel_mean, data.channel_std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8329e489-648f-44a2-9064-33647b61d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TreeDatasetFromSubset(train, all_transform=all_transform, rgb_transform=rgb_transform)\n",
    "val_dataset = TreeDatasetFromSubset(val, all_transform=prepare_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "434111be-074b-4694-a927-30e4ec6cb5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets:\n",
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Targets:\")\n",
    "idx = np.random.randint(0, 100)\n",
    "print(train_dataset[idx][1])\n",
    "plt.imshow(train_dataset[idx][0].movedim(0, -1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f628d22c-9274-4354-81b6-24fd69e760df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weights_for_balanced_classes(data, indices=None):\n",
    "    n_images = len(data.table)\n",
    "    count_per_class = np.bincount(data.table.latin, minlength=len(data.table.latin.unique()))\n",
    "    weight_per_class = (float(n_images) / count_per_class)\n",
    "    weights = weight_per_class[data.table.latin]\n",
    "    if indices:\n",
    "        weights = weights[indices]\n",
    "    return torch.tensor(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8820daa8-89f4-4703-a7fa-2cafc8702ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "\n",
    "train_weights = make_weights_for_balanced_classes(train.dataset, train.indices)\n",
    "train_sampler = WeightedRandomSampler(train_weights, len(train_weights))\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=train_sampler,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "all_loader = DataLoader(\n",
    "    dataset=TreeDatasetFromSubset(data, prepare_transform),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c57a7452-7158-4d13-b754-53a8d41bce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        stride = (2, 2) if in_channels != out_channels else (1, 1)\n",
    "\n",
    "        self.shortcut = nn.Identity()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, (1, 1), stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        self.activation = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, (3, 3), stride, padding=(1, 1), bias=False)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, (3, 3), padding=(1, 1), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        return x + residual\n",
    "\n",
    "\n",
    "class ResNetLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels),\n",
    "            ResidualBlock(out_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9774cdca-3241-40e1-8b5f-f0e3a8d9a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, out_channels=32, layer_num=3, fc_hidden=128, in_channels=3, classes_num=len(data.label_map)):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, (3, 3), padding=(1, 1), bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d((2, 2))\n",
    "        self.layers = nn.Sequential(\n",
    "            ResNetLayer(out_channels, out_channels),\n",
    "            *[ResNetLayer(2**i * out_channels, 2**(i+1) * out_channels) for i in range(layer_num - 1)],\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # predicting tree species\n",
    "        self.fc_clf = nn.Sequential(\n",
    "            nn.Linear(2**(layer_num - 1) * out_channels, fc_hidden),\n",
    "            nn.BatchNorm1d(fc_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(fc_hidden, classes_num),\n",
    "            nn.LogSoftmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layers(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x_clf = self.fc_clf(x)\n",
    "        return x_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb6cef09-26d7-44bf-be55-db8aa602b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "\n",
    "def train_loop(model, dataloader, loss_clf_fn, optimizer, step=0.05, history_loss=None, history_acc=None):\n",
    "    out = display(IPython.display.Pretty('Learning...'), display_id=True)\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    train_acc = []\n",
    "    train_loss = []\n",
    "    percentage = 0\n",
    "    \n",
    "    for batch, (X, y_clf) in enumerate(tqdm(dataloader, leave=False, desc=\"Batch #\")):\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        X = X.to(device)\n",
    "        y_clf = y_clf.to(device)\n",
    "        pred_clf = model(X)\n",
    "        loss = loss_clf_fn(pred_clf, y_clf)\n",
    "        train_acc.append((pred_clf.argmax(1) == y_clf).type(torch.float).mean().item())\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch / (num_batches - 1) >= percentage:\n",
    "            percentage = int(batch / (num_batches - 1) / step) * step\n",
    "            out.update(f'[{int(percentage * size)}/{size}] Batch NLL Loss: {loss.item():>8f}')\n",
    "        \n",
    "    if history_loss is not None:\n",
    "        history_loss.append(np.mean(train_loss))\n",
    "    if history_acc is not None:\n",
    "        history_acc.append(np.mean(train_acc))\n",
    "\n",
    "    return {'train_loss': np.mean(train_loss), 'train_acc': np.mean(train_acc)}\n",
    "\n",
    "\n",
    "def test_loop(model, dataloader,  loss_clf_fn, history_loss=None, history_acc=None):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    val_acc = []\n",
    "    val_loss = []\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y_clf) in enumerate(tqdm(dataloader, leave=False, desc=\"Batch #\")):\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "            X = X.to(device)\n",
    "            y_clf = y_clf.to(device)\n",
    "            pred_clf = model(X)\n",
    "            loss = loss_clf_fn(pred_clf, y_clf)\n",
    "            val_acc.append((pred_clf.argmax(1) == y_clf).type(torch.float).mean().item())\n",
    "            val_loss.append(loss.item())\n",
    "            correct += (pred_clf.argmax(1) == y_clf).type(torch.float).sum().item()\n",
    "\n",
    "        correct /= size\n",
    "        total_loss = np.mean(val_loss)\n",
    "        print(f\"Validation accuracy: {(100*correct):>0.1f}%, Validation NLL Loss: {total_loss:>8f} \\n\")\n",
    "\n",
    "    if history_loss is not None:\n",
    "        history_loss.append(total_loss)\n",
    "    if history_acc is not None:\n",
    "        history_acc.append(correct)\n",
    "    \n",
    "    return {'val_loss': total_loss, 'val_acc': correct}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "203adf5a-86ad-490b-8ad0-55e61bd1386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_process(train_loss, val_loss, title):\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    ax1 = plt.subplot(121)\n",
    "    ax1.plot(np.arange(0, len(train_loss)) + 1, train_loss, label='train')\n",
    "    ax1.plot(np.arange(0, len(val_loss)) + 1, val_loss, label='val')\n",
    "    ax1.legend()\n",
    "    ax1.grid()\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.set_ylabel(title.split()[0])\n",
    "    ax1.set_title(title)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c2e5600-f328-45a5-af72-5fa2927d622d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6598fb8fa64a46e78ff679677a906316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22fed5fde3db4d23a5297615e675f111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e6779821e14ac498948c93793e7404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[318/318] Batch NLL Loss: 1.242605'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 22.2%, Validation NLL Loss: 2.037320 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[318/318] Batch NLL Loss: 2.321912'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 12.2%, Validation NLL Loss: 2.078117 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[318/318] Batch NLL Loss: 2.281247'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 14.4%, Validation NLL Loss: 1.977915 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[318/318] Batch NLL Loss: 1.813586'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 20.0%, Validation NLL Loss: 1.892496 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[318/318] Batch NLL Loss: 1.468642'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 24.4%, Validation NLL Loss: 2.069724 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[318/318] Batch NLL Loss: 1.724490'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 28.9%, Validation NLL Loss: 1.943256 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[318/318] Batch NLL Loss: 1.624466'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 34.4%, Validation NLL Loss: 1.638732 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[318/318] Batch NLL Loss: 1.845715'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 31.1%, Validation NLL Loss: 1.654762 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[318/318] Batch NLL Loss: 1.899014'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 35.6%, Validation NLL Loss: 1.658050 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[318/318] Batch NLL Loss: 1.307089'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 33.3%, Validation NLL Loss: 1.736015 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[318/318] Batch NLL Loss: 1.163434'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 38.9%, Validation NLL Loss: 1.569684 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[31/318] Batch NLL Loss: 1.770712'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7d65e678604daba0de65f9cc5d0758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch #:   0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_clf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory_acc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_acc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m test_loop(net, val_dataloader, loss_clf, history_loss\u001b[38;5;241m=\u001b[39mval_loss, history_acc\u001b[38;5;241m=\u001b[39mval_acc)\n\u001b[1;32m     36\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep(val_loss[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[17], line 20\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(model, dataloader, loss_clf_fn, optimizer, step, history_loss, history_acc)\u001b[0m\n\u001b[1;32m     18\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     19\u001b[0m y_clf \u001b[38;5;241m=\u001b[39m y_clf\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 20\u001b[0m pred_clf \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_clf_fn(pred_clf, y_clf)\n\u001b[1;32m     22\u001b[0m train_acc\u001b[38;5;241m.\u001b[39mappend((pred_clf\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m y_clf)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/mambaforge/envs/experim/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/experim/lib/python3.10/site-packages/torchvision/models/efficientnet.py:343\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/experim/lib/python3.10/site-packages/torchvision/models/efficientnet.py:333\u001b[0m, in \u001b[0;36mEfficientNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 333\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m    336\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/experim/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/experim/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/experim/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/experim/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/experim/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/experim/lib/python3.10/site-packages/torchvision/models/efficientnet.py:164\u001b[0m, in \u001b[0;36mMBConv.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 164\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_res_connect:\n\u001b[1;32m    166\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstochastic_depth(result)\n",
      "File \u001b[0;32m~/mambaforge/envs/experim/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/experim/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/experim/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/experim/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/experim/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/experim/lib/python3.10/site-packages/torch/nn/modules/activation.py:396\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/experim/lib/python3.10/site-packages/torch/nn/functional.py:2058\u001b[0m, in \u001b[0;36msilu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   2056\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(silu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m-> 2058\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_label_counts = np.bincount(train.dataset.table.iloc[train.indices].latin.values, minlength=len(data.table.latin.unique()))\n",
    "# train_label_weights = ((train_label_counts + 1e-5) / train_label_counts.sum()) **-0.5\n",
    "# train_label_weights = torch.tensor(train_label_weights, dtype=torch.float, device=device)\n",
    "# loss_clf = nn.NLLLoss(train_label_weights)\n",
    "\n",
    "loss_clf = nn.NLLLoss()\n",
    "epochs = 50\n",
    "\n",
    "models_results = []\n",
    "for chan in tqdm([8]):\n",
    "    for layer_n in tqdm([3]):\n",
    "        for fc_hidden in tqdm([512]):\n",
    "            # net = ResNet18(out_channels=chan, layer_num=layer_n, fc_hidden=fc_hidden).to(device)\n",
    "            # net = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14').to(device)\n",
    "            net = models.efficientnet_v2_s(weights=\"DEFAULT\")\n",
    "            # for param in net.parameters():\n",
    "            #     net.requires_grad = False\n",
    "            net.classifier = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(1280, len(data.label_map)),\n",
    "                nn.LogSoftmax(dim=1),\n",
    "            )\n",
    "            net.to(device)\n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=2e-4)\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5, min_lr=1e-7)\n",
    "\n",
    "            train_acc, train_loss = [], []\n",
    "            val_acc, val_loss = [], []\n",
    "\n",
    "            models_results.append({\"first_out_channel\": chan, \"layer_num\": layer_n, \"fc_hidden\": fc_hidden})\n",
    "            for epoch in range(epochs):\n",
    "                print(f\"Epoch {epoch+1}\")\n",
    "                print(\"-------------------------------\")\n",
    "                train_loop(net, train_dataloader, loss_clf, optimizer, history_loss=train_loss, history_acc=train_acc)\n",
    "                test_loop(net, val_dataloader, loss_clf, history_loss=val_loss, history_acc=val_acc)\n",
    "                scheduler.step(val_loss[-1])\n",
    "            \n",
    "            models_results[-1][f\"train_{target_column}_acc\"] = train_acc\n",
    "            models_results[-1][f\"train_{target_column}_loss\"] = train_loss\n",
    "            models_results[-1][f\"val_{target_column}_acc\"] = val_acc\n",
    "            models_results[-1][f\"val_{target_column}_loss\"] = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b21367-e782-419c-b63f-a2eb546b9fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(models_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8a219b-28c4-4cd8-a6be-5236195a3046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanded_df = results_df.set_index([\"first_out_channel\"]).apply(pd.Series.explode).reset_index()\n",
    "\n",
    "# expanded_df.index.name = \"Epoch\"\n",
    "# expanded_df.index = expanded_df.index + 1\n",
    "# expanded_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ffb500-0e1e-44b1-8822-72f51bf5329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(results_df)):\n",
    "    row = results_df.iloc[i]\n",
    "    print(row[:3])\n",
    "    plot_learning_process(row.train_latin_loss, row.val_latin_loss, \"NegativeLogLikelihood Loss\")\n",
    "    plot_learning_process(row.train_latin_acc, row.val_latin_acc, \"Accuracy of species prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367550fa-e15a-4059-93cd-69a025635239",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TreeDatasetFromSubset(test, prepare_transform)\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2a2a2d-5055-4de7-b3fc-50444272ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"{target_column}_prediction_model.pt\"\n",
    "assert not os.path.exists(PATH), \"There is a checkpoint already! Remove this assert to override\"\n",
    "test_results = test_loop(net, test_dataloader, loss_clf)\n",
    "torch.save({\n",
    "    'epoch': epochs,\n",
    "    'model_state_dict': net.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': test_results[\"val_loss\"],\n",
    "    'acc': test_results[\"val_acc\"]\n",
    "},\n",
    "    PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f0d2b-b2a7-45c8-b092-61baeaf4053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18(out_channels=8, layer_num=3, fc_clf_hidden=512).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "acc = checkpoint['acc']\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057d62da-449f-4d34-adc7-285e5a925ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bf3fb0-939b-4ec7-97f3-be660da710b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "trues = []\n",
    "with torch.no_grad():\n",
    "    for X, y_clf in tqdm(val_dataloader, leave=False, desc=\"Batch #\"):\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        X = X.to(device)\n",
    "        y_clf = y_clf.to(device)\n",
    "        pred = net(X).argmax(1)\n",
    "        preds.extend(pred.tolist())\n",
    "        trues.extend(y_clf.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b817e83-1afa-4ed6-be3a-cbc006968872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplots(1, 2, sharex=True, figsize=(12, 6))\n",
    "plt.hist(trues, bins=50, label=\"true\")\n",
    "plt.hist(preds, bins=50, label=\"predictions\", alpha=0.75)\n",
    "plt.xticks(ticks=range(len(data.label_map)), labels=list(data.label_map.keys()), rotation=90)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcd9417-ee04-460e-86db-c4e036bfed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(confusion_matrix(trues, preds), index=data.label_map.keys(), columns=data.label_map.keys())\n",
    "plt.figure(figsize = (10, 7))\n",
    "sns.heatmap(df_cm, cmap=\"flare\", annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f0910e-3bd1-4e44-adc3-26928ce1e446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:experim] *",
   "language": "python",
   "name": "conda-env-experim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
